{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMBjBf97hR2ZBJlWvS+IlY4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karasu1982/e-Stat_Download/blob/main/e_Stat%E3%83%80%E3%82%A6%E3%83%B3%E3%83%AD%E3%83%BC%E3%83%89.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 環境設定"
      ],
      "metadata": {
        "id": "ZN4z8pR0weK0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DD81bbqVwdod"
      },
      "outputs": [],
      "source": [
        "!pip install pykakasi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 標準ライブラリ\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "import xlrd\n",
        "import zipfile\n",
        "import urllib\n",
        "import requests\n",
        "import functools\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "from tqdm import tqdm\n",
        "import os"
      ],
      "metadata": {
        "id": "K3vpXrWszjkn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 関数定義"
      ],
      "metadata": {
        "id": "sytOD-kcz-os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EstatRestAPI_URLParser:\n",
        "    \"\"\"\n",
        "    This is a simple python module class for e-Stat API (ver.3.0).\n",
        "    See more details at https://www.e-stat.go.jp/api/api-info/e-stat-manual3-0\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, api_version=None, app_id=None):\n",
        "        # base url\n",
        "        self.base_url = \"https://api.e-stat.go.jp/rest\"\n",
        "\n",
        "        # e-Stat REST API Version\n",
        "        if api_version is None:\n",
        "            self.api_version = \"3.0\"\n",
        "        else:\n",
        "            self.api_version = api_version\n",
        "\n",
        "        # Application ID\n",
        "        if app_id is None:\n",
        "            self.app_id = \"<アプリケーションID>\"\n",
        "        else:\n",
        "            self.app_id = app_id\n",
        "\n",
        "    def getStatsListURL(self, params_dict, format=\"csv\"):\n",
        "        \"\"\"\n",
        "        2.1 統計表情報取得 (HTTP GET)\n",
        "        \"\"\"\n",
        "        params_str = urllib.parse.urlencode(params_dict)\n",
        "        if format == \"xml\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getStatsList?{params_str}\"\n",
        "            )\n",
        "        elif format == \"json\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/json/getStatsList?{params_str}\"\n",
        "            )\n",
        "        elif format == \"jsonp\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/jsonp/getStatsList?{params_str}\"\n",
        "            )\n",
        "        elif format == \"csv\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getSimpleStatsList?{params_str}\"\n",
        "            )\n",
        "        return url\n",
        "\n",
        "    def getMetaInfoURL(self, params_dict, format=\"csv\"):\n",
        "        \"\"\"\n",
        "        2.2 メタ情報取得 (HTTP GET)\n",
        "        \"\"\"\n",
        "        params_str = urllib.parse.urlencode(params_dict)\n",
        "        if format == \"xml\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getMetaInfo?{params_str}\"\n",
        "            )\n",
        "        elif format == \"json\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/json/getMetaInfo?{params_str}\"\n",
        "            )\n",
        "        elif format == \"jsonp\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/jsonp/getMetaInfo?{params_str}\"\n",
        "            )\n",
        "        elif format == \"csv\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getSimpleMetaInfo?{params_str}\"\n",
        "            )\n",
        "        return url\n",
        "\n",
        "    def getStatsDataURL(self, params_dict, format=\"csv\"):\n",
        "        \"\"\"\n",
        "        2.3 統計データ取得 (HTTP GET)\n",
        "        \"\"\"\n",
        "        params_str = urllib.parse.urlencode(params_dict)\n",
        "        if format == \"xml\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getStatsData?{params_str}\"\n",
        "            )\n",
        "        elif format == \"json\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/json/getStatsData?{params_str}\"\n",
        "            )\n",
        "        elif format == \"jsonp\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/jsonp/getStatsData?{params_str}\"\n",
        "            )\n",
        "        elif format == \"csv\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getSimpleStatsData?{params_str}\"\n",
        "            )\n",
        "        return url\n",
        "\n",
        "    def postDatasetURL(self):\n",
        "        \"\"\"\n",
        "        2.4 データセット登録 (HTTP POST)\n",
        "        \"\"\"\n",
        "        url = (\n",
        "            f\"{self.base_url}/{self.api_version}\"\n",
        "            \"/app/postDataset\"\n",
        "        )\n",
        "        return url\n",
        "\n",
        "    def refDataset(self, params_dict, format=\"xml\"):\n",
        "        \"\"\"\n",
        "        2.5 データセット参照 (HTTP GET)\n",
        "        \"\"\"\n",
        "        params_str = urllib.parse.urlencode(params_dict)\n",
        "        if format == \"xml\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                + f\"/app/refDataset?{params_str}\"\n",
        "            )\n",
        "        elif format == \"json\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/json/refDataset?{params_str}\"\n",
        "            )\n",
        "        elif format == \"jsonp\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/jsonp/refDataset?{params_str}\"\n",
        "            )\n",
        "        return url\n",
        "\n",
        "    def getDataCatalogURL(self, params_dict, format=\"xml\"):\n",
        "        \"\"\"\n",
        "        2.6 データカタログ情報取得 (HTTP GET)\n",
        "        \"\"\"\n",
        "        params_str = urllib.parse.urlencode(params_dict)\n",
        "        if format == \"xml\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getDataCatalog?{params_str}\"\n",
        "            )\n",
        "        elif format == \"json\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/json/getDataCatalog?{params_str}\"\n",
        "            )\n",
        "        elif format == \"jsonp\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/jsonp/getDataCatalog?{params_str}\"\n",
        "            )\n",
        "        return url\n",
        "\n",
        "    def getStatsDatasURL(self, params_dict, format=\"xml\"):\n",
        "        \"\"\"\n",
        "        2.7 統計データ一括取得 (HTTP GET)\n",
        "        \"\"\"\n",
        "        params_str = urllib.parse.urlencode(params_dict)\n",
        "        if format == \"xml\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getStatsDatas?{params_str}\"\n",
        "            )\n",
        "        elif format == \"json\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/json/getStatsDatas?{params_str}\"\n",
        "            )\n",
        "        elif format == \"csv\":\n",
        "            url = (\n",
        "                f\"{self.base_url}/{self.api_version}\"\n",
        "                f\"/app/getSimpleStatsDatas?{params_str}\"\n",
        "            )\n",
        "        return url"
      ],
      "metadata": {
        "id": "WLbi3BJmzwpA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_json(url):\n",
        "    \"\"\"\n",
        "    Request a HTTP GET method to the given url (for REST API)\n",
        "    and return its response as the dict object.\n",
        "\n",
        "    Args:\n",
        "    ====\n",
        "    url: string\n",
        "        valid url for REST API\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"HTTP GET\", url)\n",
        "        r = requests.get(url)\n",
        "        json_dict = r.json()\n",
        "        return json_dict\n",
        "    except requests.exceptions.RequestException as error:    \n",
        "        print(error)"
      ],
      "metadata": {
        "id": "mGO2BVMtz1xQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_csv(url, filepath, enc=\"utf-8\", dec=\"utf-8\", logging=False):\n",
        "    \"\"\"\n",
        "    Request a HTTP GET method to the given url (for REST API)\n",
        "    and save its response as the csv file.\n",
        "\n",
        "    url: string\n",
        "        valid url for REST API\n",
        "    filepathe: string\n",
        "        valid path to the destination file\n",
        "    enc: string\n",
        "        encoding type for a content in a given url\n",
        "    dec: string\n",
        "        decoding type for a content in a downloaded file\n",
        "            dec = 'utf-8' for general env\n",
        "            dec = 'sjis'  for Excel on Win\n",
        "            dec = 'cp932' for Excel with extended JP str on Win\n",
        "    logging: True/False\n",
        "        flag whether putting process log\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if logging:\n",
        "            print(\"HTTP GET\", url)\n",
        "        r = requests.get(url, stream=True)\n",
        "        with open(filepath, 'w', encoding=enc) as f:\n",
        "            f.write(r.content.decode(dec))\n",
        "    except requests.exceptions.RequestException as error:\n",
        "        print(error)\n",
        "\n",
        "\n",
        "def download_all_csv(\n",
        "        urls,\n",
        "        filepathes,\n",
        "        max_workers=10,\n",
        "        enc=\"utf-8\",\n",
        "        dec=\"utf-8\"):\n",
        "    \"\"\"\n",
        "    Request some HTTP GET methods to the given urls (for REST API)\n",
        "    and save each response as the csv file.\n",
        "    (!! This method uses multi threading when calling HTTP GET requests\n",
        "    and downloading files in order to improve the processing speed.)\n",
        "\n",
        "    urls: list of strings\n",
        "        valid urls for REST API\n",
        "    filepathes: list of strings\n",
        "        valid pathes to the destination file\n",
        "    max_workers: int\n",
        "        max number of working threads of CPUs within executing this method.\n",
        "    enc: string\n",
        "        encoding type for a content in a given url\n",
        "    dec: string\n",
        "        decoding type for a content in a downloaded file\n",
        "            dec = 'utf-8' for general env\n",
        "            dec = 'sjis'  for Excel on Win\n",
        "            dec = 'cp932' for Excel with extended JP str on Win\n",
        "    logging: True/False\n",
        "    \"\"\"\n",
        "    func = functools.partial(download_csv, enc=enc, dec=dec)\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        results = list(\n",
        "            tqdm(executor.map(func, urls, filepathes), total=len(urls))\n",
        "        )\n",
        "        del results"
      ],
      "metadata": {
        "id": "nb8GgRvxz3zG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "estatapi_url_parser = EstatRestAPI_URLParser()  # URL Parser\n",
        "\n",
        "def search_tables(appId, statsCode):\n",
        "    \"\"\"\n",
        "    Prams (dictionary) to search eStat tables.\n",
        "    For more details, see also\n",
        "    https://www.e-stat.go.jp/api/api-info/e-stat-manual3-0#api_3_2\n",
        "\n",
        "        - appId: Application ID (*required)\n",
        "        - lang: 言語(J:日本語, E:英語)\n",
        "        - surveyYears: 調査年月 (YYYYY or YYYYMM or YYYYMM-YYYYMM)\n",
        "        - openYears: 調査年月と同様\n",
        "        - statsField: 統計分野 (2桁:統計大分類, 4桁:統計小分類)\n",
        "        - statsCode: 政府統計コード (8桁)\n",
        "        - searchWord: 検索キーワード\n",
        "        - searchKind: データの種別 (1:統計情報, 2:小地域・地域メッシュ)     \n",
        "        - collectArea: 集計地域区分 (1:全国, 2:都道府県, 3:市区町村)        \n",
        "        - explanationGetFlg: 解説情報有無(Y or N)\n",
        "        - ...\n",
        "    \"\"\"\n",
        "    params_dict = {\n",
        "        \"appId\": appId,\n",
        "        \"lang\": \"J\",\n",
        "        \"statsCode\": statsCode,\n",
        "        #\"searchWord\": \"社会・人口統計体系\",  # \"統計でみる市区町村のすがた\",\n",
        "        \"searchKind\": 1,\n",
        "        \"collectArea\": 3,\n",
        "        \"explanationGetFlg\": \"N\"\n",
        "    }\n",
        "\n",
        "    url = estatapi_url_parser.getStatsListURL(params_dict, format=\"json\")   \n",
        "    json_dict = get_json(url)\n",
        "    # pprint(json_dict)\n",
        "\n",
        "    if json_dict['GET_STATS_LIST']['DATALIST_INF']['NUMBER'] != 0:\n",
        "        tables = json_dict[\"GET_STATS_LIST\"][\"DATALIST_INF\"][\"TABLE_INF\"]\n",
        "    else:\n",
        "        tables = []\n",
        "    return tables\n",
        "\n",
        "\n",
        "def parse_table_id(table):\n",
        "    return table[\"@id\"]\n",
        "\n",
        "\n",
        "def parse_table_raw_size(table):\n",
        "    return table[\"OVERALL_TOTAL_NUMBER\"]\n",
        "\n",
        "\n",
        "def parse_table_urls(table_id, table_raw_size, csv_raw_size=100000):\n",
        "    urls = []\n",
        "    for j in range(0, int(table_raw_size / csv_raw_size) + 1):\n",
        "        start_pos = j * csv_raw_size + 1\n",
        "        params_dict = {\n",
        "            \"appId\": appId,  # Application ID\n",
        "            \"lang\": \"J\",  # 言語 (J: 日本語, E: 英語)\n",
        "            \"statsDataId\": str(table_id),  # 統計表ID\n",
        "            \"startPosition\": start_pos,  # 開始行\n",
        "            \"limit\": csv_raw_size,  # データ取得件数\n",
        "            \"explanationGetFlg\": \"N\",  # 解説情報有無(Y or N)\n",
        "            \"annotationGetFlg\": \"N\",  # 注釈情報有無(Y or N)\n",
        "            \"metaGetFlg\": \"N\",  # メタ情報有無(Y or N)\n",
        "            \"sectionHeaderFlg\": \"2\",  # CSVのヘッダフラグ(1:取得, 2:取得無)\n",
        "        }\n",
        "        url = estatapi_url_parser.getStatsDataURL(params_dict, format=\"csv\")\n",
        "        urls.append(url)\n",
        "    return urls"
      ],
      "metadata": {
        "id": "st7D9jEQz6Ym"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 処理実行"
      ],
      "metadata": {
        "id": "Pyqd0xRW0H7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "appId = \"＜アプリケーションID＞\"\n",
        "statsCode = \"00200521\" # 統計番号"
      ],
      "metadata": {
        "id": "D1h5yRD_0KhH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_RAW_SIZE = 100000\n",
        "\n",
        "# list of tables\n",
        "tables = search_tables(appId, statsCode)\n",
        "\n",
        "# extract all table ids\n",
        "if len(tables) == 0:\n",
        "    print(\"No tables were found.\")\n",
        "elif len(tables) == 1:\n",
        "    table_ids = [parse_table_id(tables[0])]\n",
        "else:\n",
        "    table_ids = list(map(parse_table_id, tables))\n",
        "\n",
        "# list of urls\n",
        "table_urls = []\n",
        "table_raw_size = list(map(parse_table_raw_size, tables))\n",
        "for i, table_id in enumerate(table_ids):\n",
        "    table_urls = table_urls + parse_table_urls(table_id, table_raw_size[i])\n",
        "\n",
        "# list of filepathes\n",
        "filepathes = []\n",
        "table_names = []\n",
        "table_numbers = []\n",
        "\n",
        "for i, table_id in enumerate(table_ids):\n",
        "    tb = tables[i][\"TITLE_SPEC\"][\"TABLE_NAME\"]\n",
        "    table_name = tables[i][\"@id\"]\n",
        "    table_dir = f\"./downloads/tmp/{table_name}_{table_id}\"\n",
        "    os.makedirs(table_dir, exist_ok=True)\n",
        "\n",
        "    fps=[]\n",
        "    for j in range(0, int(table_raw_size[i] / CSV_RAW_SIZE) + 1):\n",
        "        filepath = f\"{table_dir}/{table_name}_{table_id}_{j}.csv\"\n",
        "        fps.append(filepath)\n",
        "        #filepathes.append(filepath)\n",
        "\n",
        "    table_numbers.append(table_name)\n",
        "    table_names.append(tb)\n",
        "    filepathes.append(fps)\n",
        "\n",
        "download_all_csv(table_urls, [item for l in filepathes for item in l], max_workers=30)"
      ],
      "metadata": {
        "id": "RaNz7ejj0M0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pykakasi\n",
        "kakasi = pykakasi.kakasi() # インスタンスの作成\n",
        "kakasi.setMode('H', 'a') # ひらがなをローマ字に変換するように設定\n",
        "kakasi.setMode('K', 'a') # カタカナをローマ字に変換するように設定\n",
        "kakasi.setMode('J', 'a') # 漢字をローマ字に変換するように設定\n",
        "conversion = kakasi.getConverter() # 上記モード設定の適用\n",
        "\n",
        "import re\n",
        "regex = re.compile(\"\\d\", flags=0)\n",
        "\n",
        "\n",
        "df_names = pd.DataFrame()\n",
        "\n",
        "for table_name, fps, tb_num in zip(table_names[78:], filepathes[78:], table_numbers[78:]):\n",
        "\n",
        "  df_merged = pd.DataFrame()\n",
        "\n",
        "  # 分割してダウンロードしたファイルを、pandas化後に結合\n",
        "  for filepath in fps:\n",
        "    df = pd.read_csv(filepath)\n",
        "\n",
        "    # 日本語の変数名はBQに書き込めないため、ざっくり英語化\n",
        "    col_en = []\n",
        "    col_ja = list(df.columns)\n",
        "\n",
        "    for col in col_ja:\n",
        "\n",
        "      trans_en = conversion.do(col)\n",
        "      trans_en = trans_en.replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\" \",\"_\").replace(\"-\",\"\").replace(\"'\",\"\").replace(\".\",\"\")\n",
        "      trans_en = trans_en.replace(\"（\",\"\").replace(\"）\",\"\").replace(\"，\",\"\").replace(\"　\",\"_\").replace(\"－\",\"\").replace(\"～\",\"\").replace(\"・\",\"\")\n",
        "\n",
        "      # 数値始まりの変数名はNGになるため、N_を付与\n",
        "      if regex.search(trans_en[1]):\n",
        "        trans_en = \"N_\"+trans_en\n",
        "\n",
        "      col_en.append(trans_en)\n",
        "\n",
        "    # 同じ列名になった時に、_2をつける\n",
        "    col_en = [x + ['', '_2'][x in col_en[0:i]] for i, x in enumerate(col_en)]\n",
        "\n",
        "    df.columns = col_en  \n",
        "    df[\"table_name\"] = table_name\n",
        "\n",
        "    df_merged = df_merged.append(df)\n",
        "\n",
        "  df_merged.to_gbq(f\"{DATASET}.table_{tb_num}\",f\"{PROJECT}\", if_exists=\"replace\")\n",
        "\n",
        "  df_name = pd.DataFrame(zip(col_ja, col_en), columns=[\"col_ja\", \"col_en\"])\n",
        "  df_name[\"table_name\"] = table_name\n",
        "  df_name[\"table_id\"] = tb_num\n",
        "  df_names = df_names.append(df_name)"
      ],
      "metadata": {
        "id": "mmjBWFnG0Qlz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}